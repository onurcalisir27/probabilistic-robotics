\section{Mobile Robot Localization: Markov and Gaussian}

Mobile robot localization is the problem of determining the pose of a robot relative to a given map of the environment. It is often called position estimation. Mobile robot localization is an instance of the general localization problem, which is the most basic perceptual problem in robotics. \\

Mobile robot localization can be seen as a problem of coordinate transformation. Maps are described in a global coordinate system, which is independent of a robot’s pose.
Localization is the process of establishing correspondence between the map coordinate system and the robot’s local coordinate system.
Knowing this coordinate transformation enables the robot to express the location of objects of interest within its own coordinate frame, a necessary prerequisite for robot navigation.\\

Unfortunately, the pose can usualy not be sensed directly, therefore has to be inferred from data. A key difficulty arises from the fact that a single sensor measurement is usually insufficient to determine the pose.
Instead the robot has to integrate data over time to determine its pose.

\subsection{Markov Localization}

The straightforward application of Bayes filters to the localization problem is called Markov localization.
Notice that Markov localization also requires a map $m$ as input. The map plays a role in the measurement model $\pcond{z_t}{x_t, m}$.
It often, but not always, is incorporated in the motion model $\pcond{x_t}{x_{t-1}, u_t, m}$ as well.
Just like the Bayes filter, Markov localization transforms a probabilistic belief at time $t - 1$ into a belief at time $t$.
Markov localization addresses the global localization problem, the position tracking problem, and the kidnapped robot problem in static environments.

\begin{algorithm}[H]
\caption{Markov Localization}
\KwInput{$bel(x_{t-1})$, $\control_t$, $\obs_t$, $m$}
\KwOutput{$bel(x_t)$}

\BlankLine
for all $x_t$ do \\
$ \quad \bar{bel}(x_t) = \int{\pcond{x_t}{u_t, x_{t-1}, m} bel(x_{t-1})} dx_{t-1} $ \\
$\quad bel(x_t) = \eta \pcond{z_t}{x_t, m} \bar{bel}(x_t)$\\
endfor
\BlankLine
\Return{$bel(x_{t})$}
\end{algorithm}
The initial belief, $bel(x_0)$, reflects the initial knowledge of the robot’s pose. It is set differently depending on the type of localization problem.
\begin{itemize}
  \item \textbf{Position tracking}. If the initial pose is known, $bel(x_0)$ is initialized by a point-mass distribution. Let $\bar{x}_0$ denote the (known) initial pose. Then: $bel(x_0) = 1$

  \item \textbf{Global localization}. If the initial pose is unknown, $bel(x_0)$ is initialized by a uniform distribution over the space of all legal poses in the map:
    \begin{equation}
      bel(x_0) = \frac{1}{\|X\|}
      \label{eq:global markov localization}
    \end{equation}
    where $\|X\|$ stands for the volume of the space of all poses within the map.
  \item \textbf{Other}. Partial knowledge of the robot’s position can usually easily be transformed into an appropriate initial distribution
\end{itemize}

\newpage

\subsection{EKF Localization}
The extended Kalman filter localization algorithm, or EKF localization, is a special case of Markov localization.
EKF localization represents beliefs $bel(x_t)$ by their first and second moment, the mean $\mu_t$ and the covariance $\Sigma_t$.\\

Our EKF localization algorithm assumes that the map is represented by a collection of features.
At any point in time $t$, the robot gets to observe a vector of ranges and bearings to nearby features: $z_t = \{zt 1, zt 2 ,...\}$.
We begin with a localization algorithm in which all features are uniquely identifiable.
The identity of a feature is expressed by a set of \textit{correspondence variables}, denoted $c_t^i$, one for each feature vector $z_t^i$.\\

Let us first assume that the correspondences are known. We then progress to a more general version that allows for ambiguity among features.
The second, more general version applies a maximum likelihood estimator to estimate the value of the latent correspondence variable, and uses the result of this estimation as if it were ground truth.

\subsubsection{The EKF Localization with Known Correspondences}
We now discuss a concrete implementation of the EKF for feature based maps.
Our feature based maps consist of point landmarks, the common measurement model discussed in Chapter 6.6 will be used.
We also use the velocity motion model defined in previous section.\\

Algorithm requires as its input a Gaussian estimate of the robot pose at time $t-1$, with mean $\mu_{t-1}$ and covariance $\Sigma_{t-1}$.
Further, it requires a control $u_t$, a map $m$, and a set of features $z_t = \{ z_t^1, z_t^2, \dots\}$ measured at time $t$, along with the correspondence variables $c_t = \{c_t^1, c_t^2, \dots\}$.
Its output is a new, revised estimate $\mu_t, \Sigma_t$, along with the likelihood of the feature observation $p_{z_t}$.\\

\begin{algorithm}[H]
\caption{EKF Localization with known correspondences}
\KwInput{$\mu_{t-1},\ \Sigma_{t-1},\ u_t,\ z_t,\ c_t,\ m$}
\KwOutput{$\mu_t, \Sigma_t, p_{z_t}$}
\BlankLine
$\theta = \mu_{t-1, \theta}$\\
$G_t = \begin{pmatrix} 1 & 0 & -\frac{v_t}{\omega_t}\cos \theta + \frac{v_t}{\omega_t}\cos (\theta + \omega \dt) \\ 0 & 1 & -\frac{v_t}{\omega_t}\sin \theta + \frac{v_t}{\omega_t}\sin (\theta + \omega \dt) \\ 0 & 0 & 1 \end{pmatrix} $\\
\BlankLine
$V_t = \begin{pmatrix}\frac{-\sin\theta + \sin(\theta+\omega\dt)}{\omega_t} &  \frac{v_t(\sin\theta - \sin(\theta+\omega\dt))}{\omega_t^2} + \frac{v_t\cos(\theta+\omega\dt) \dt}{\omega_t} \\
\frac{\cos\theta - \cos(\theta+\omega\dt)}{\omega_t} & -\frac{v_t(\cos\theta - \cos(\theta+\omega\dt))}{\omega_t^2} + \frac{v_t\sin(\theta+\omega\dt) \dt}{\omega_t} \\
0 & \dt \end{pmatrix}$\\
\BlankLine
$M_t = \begin{pmatrix} \alpha_1 v_t^2 + \alpha_2 \omega_t^2 & 0 \\ 0 & \alpha_3 v_t^2 + \alpha_4\omega_t^2 \end{pmatrix}$\\
\BlankLine
$\bar{\mu}_t = \mu_{t-1} + $\\
\BlankLine
$\bar{\Sigma}_t = G_t \Sigma_{t-1} G_t^T + V_t M_t V_t^T$\\
\BlankLine
$Q_t = \begin{pmatrix} \sigma_r^2 & 0 & 0 \\ 0 & \sigma_{\phi}^2 & 0 \\ 0 & 0 & \sigma_s^2 \end{pmatrix}$\\
\BlankLine
for all observed features $z_t^i = (r_t^i \phi_t^i s_t^i)^T$ do
$\quad j = c_t^i $\\
$\quad q = (m_{j,x} - \bar{\mu}_{t,x})^2 + (m_{j,y} - \bar{\mu}_{t,y})^2$\\
\BlankLine
$\quad \hat{z}_t^i = \begin{pmatrix} \sqrt{q} \\ \atantwo (m_{j,y - \bar{mu}_{t,y}}, m_{j,x} - \bar{\mu}_{t,x}) - \bar{\mu}_{t, \theta} \\ m_{j,s} \end{pmatrix}$ \\
\BlankLine
$\quad H_t^i = \begin{pmatrix} -\frac{m_{j,x} - \bar{\mu}_{t,x}}{\sqrt{q}} & -\frac{m_{j,y} - \bar{\mu}_{t,y}}{\sqrt{q}} & 0 \\
                                -\frac{m_{j,y} - \bar{\mu}_{t,y}}{{q}} & -\frac{m_{j,x} - \bar{\mu}_{t,x}}{{q}} & -1  \\
                               0 & 0 & 0 \end{pmatrix}$ \\
\BlankLine
$\quad S_t^i = H_t^i \bar{\Sigma}_t [H_t^i]^T + Q_t$\\
$\quad K_t^i = \bar{\Sigma_t} [H_t^i]^T [S_t^i]^{-1}$\\
$\quad \bar{\mu}_t = \bar{\mu_t} + K_t^i (z_t^i - \hat{z_t^i})$\\
$\quad \bar{\Sigma}_t = (I - K_t^i H_t^i) \bar{\Sigma}_t$ \\
endfor
\BlankLine
$\mu_t = \bar{\mu}_t$\\
$\Sigma_t = \bar{\mu}_t$\\
\BlankLine
$p_{z_t} = \prod_i \det(2\pi S_t^i)^{-\frac{1}{2}} \exp \left\{ -\frac{1}{2} (z_t^i - \hat{z}_t^i) [S_t^i]^{-1} (z_t^i - \hat{z}_t^i) \right\}$
\BlankLine
\Return{$\mu_t, \Sigma_t, p_{z_t}$}
\end{algorithm}


\subsubsection{EKF Localization with Unknown Correspondences}

\begin{algorithm}[H]
\caption{EKF Localization}
\KwInput{$\mu_{t-1},\ \Sigma_{t-1},\ u_t,\ z_t,\ m$}
\KwOutput{$\mu_t, \Sigma_t, p_{z_t}$}
\BlankLine
$\theta = \mu_{t-1, \theta}$\\
\BlankLine
$G_t = \begin{pmatrix} 1 & 0 & -\frac{v_t}{\omega_t}\cos \theta + \frac{v_t}{\omega_t}\cos (\theta + \omega \dt) \\ 0 & 1 & -\frac{v_t}{\omega_t}\sin \theta + \frac{v_t}{\omega_t}\sin (\theta + \omega \dt) \\ 0 & 0 & 1 \end{pmatrix} $\\
\BlankLine
$V_t = \begin{pmatrix}\frac{-\sin\theta + \sin(\theta+\omega\dt)}{\omega_t} &  \frac{v_t(\sin\theta - \sin(\theta+\omega\dt))}{\omega_t^2} + \frac{v_t\cos(\theta+\omega\dt) \dt}{\omega_t} \\
\frac{\cos\theta - \cos(\theta+\omega\dt)}{\omega_t} & -\frac{v_t(\cos\theta - \cos(\theta+\omega\dt))}{\omega_t^2} + \frac{v_t\sin(\theta+\omega\dt) \dt}{\omega_t} \\
0 & \dt \end{pmatrix}$\\
\BlankLine
$M_t = \begin{pmatrix} \alpha_1 v_t^2 + \alpha_2 \omega_t^2 & 0 \\ 0 & \alpha_3 v_t^2 + \alpha_4\omega_t^2 \end{pmatrix}$\\
\BlankLine
$\bar{\mu}_t = \mu_{t-1} + $\\
\BlankLine
$\bar{\Sigma}_t = G_t \Sigma_{t-1} G_t^T + V_t M_t V_t^T$\\
\BlankLine
$Q_t = \begin{pmatrix} \sigma_r^2 & 0 & 0 \\ 0 & \sigma_{\phi}^2 & 0 \\ 0 & 0 & \sigma_s^2 \end{pmatrix}$\\
\BlankLine
for all observed features $z_t^i = (r_t^i \phi_t^i s_t^i)^T$ do\\
$\quad$ for all landmarks $k$ in the map $m$ do\\

$\qquad q = (m_{k,x} - \bar{\mu}_{t,x})^2 + (m_{k,y} - \bar{\mu}_{t,y})^2$\\
\BlankLine
$\qquad \hat{z}_t^k = \begin{pmatrix} \sqrt{q} \\ \atantwo (m_{k,y} - \bar{\mu}_{t,y}, m_{k,x} - \bar{\mu}_{t,x}) - \bar{\mu}_{t, \theta} \\ m_{k,s} \end{pmatrix}$ \\
\BlankLine
$\qquad H_t^k = \begin{pmatrix} -\frac{m_{k,x} - \bar{\mu}_{t,x}}{\sqrt{q}} & -\frac{m_{k,y} - \bar{\mu}_{t,y}}{\sqrt{q}} & 0 \\
                                -\frac{m_{k,y} - \bar{\mu}_{t,y}}{{q}} & -\frac{m_{k,x} - \bar{\mu}_{t,x}}{{q}} & -1  \\
                               0 & 0 & 0 \end{pmatrix}$ \\
\BlankLine
$\qquad S_t^k = H_t^k \bar{\Sigma}_t [H_t^k]^T + Q_t$\\

$\quad$ endfor \\

\BlankLine
$\quad j(i) = \underset{k}{\text{argmax}} \ \ \det(2\pi S_t^k)^{-\frac{1}{2}} \ \exp \left\{-\frac{1}{2} (z_t^i - \hat{z}_t^k)^T [S_t^k]^{-1} (z_t^i - \hat{z}_t^k)\right\}$\\
$\quad K_t^i = \bar{\Sigma}_t [H_t^{j(i)}]^T [S_t^{j(i)}]^{-1}$\\
$\quad \bar{\mu}_t = \bar{\mu}_t + K_t^i (z_t^i - \hat{z_t^{j(i)}})$\\
$\quad \bar{\Sigma}_t = (I - K_t^i H_t^{j(i)}) \bar{\Sigma}_t$ \\
endfor
\BlankLine
$\mu_t = \bar{\mu}_t$\\
$\Sigma_t = \bar{\mu}_t$\\
\BlankLine
\BlankLine
\Return{$\mu_t, \Sigma_t$}
\end{algorithm}

\newpage

\subsubsection{Practical Consideration}
\begin{itemize}
  \item \textbf{Efficient search}. First, it is often impractical to loop through all landmarks $k$ in the map, as is done by our EKF localization algorithm for unknown correspondences.
   Often, there exist simple tests to identify plausible candicate landmark (e.g., by simply projectiing the measurement into $x-y$ space), enabling one to rule out all but a constant
   number of candiates. Such algorithms can be orders of magnitude faster than our naive implementation.

  \item \textbf{Mutual exclusion}. A key limitation of our implementation arises from our assumed independence of feature noise in the EKF (and, by inheritance, the MHT).

\end{itemize}



