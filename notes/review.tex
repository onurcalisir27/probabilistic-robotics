\documentclass[14pt,letterpaper]{article}

% ============ Page Layout ============
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{Midterm Review}
\lhead{Onur Calisir}
\rfoot{Page \thepage}

% ============ Math Packages ============
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}  % Enhanced math (e.g., dcases)
\usepackage{bm}         % Bold math symbols (\bm{x})
\usepackage{bbm}        % Blackboard bold for indicators

% ============ Graphics & Figures ============
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{bayesnet, arrows.meta, positioning}
\usepackage{float}
% ============ Algorithms ============
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}

% ============ Code Blocks ============
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

% ============ Theorem Environments ============
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{example}{Example}[section]

% ============ Custom Commands ============
% Probability & Statistics
\newcommand{\prob}[1]{\mathbb{P}\left(#1\right)}
\newcommand{\expect}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\var}[1]{\text{Var}\left(#1\right)}
\newcommand{\cov}[2]{\text{Cov}\left(#1, #2\right)}

% Distributions
\newcommand{\normal}[2]{\mathcal{N}\left(#1; #2\right)}
\newcommand{\uniform}[2]{\mathcal{U}\left(#1; #2\right)}

% Shortcuts
\newcommand{\pcond}[2]{p(#1 \mid #2)}

% State space notation
\newcommand{\state}{\bm{x}}
\newcommand{\obs}{\bm{z}}
\newcommand{\control}{\bm{u}}
\newcommand{\noise}{\bm{w}}

% ============ Hyperlinks ============
\usepackage[colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue]{hyperref}

% ============ Title Info ============
\title{Probabilistic Robotics - Midterm Study Notes}
\author{Onur Calisir}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage
\input{bayes_filter.tex}
\newpage
\input{gaussian_filters.tex}
\newpage
\input{transforms.tex}
\newpage
\section{Robot Motion}

\subsection{Kinematic Configuration}
\textit{Kinematics} is the calculus of describing the effect of control actions oon the configuration of a robot. The configuration of a rigid mobile robot is commonly
described by six variables, its three-dimensional Cartesian coordinates, and its three Euler angles (roll, pitch yaw) relative to an external coordinate frame.
We will stick with mobile robots operating in planar environments, whose kinematic state is summarized by three variables, referred to as pose in this context.

The pose of a mobile robot operating in a plane is comprised of two-dimensional planar coordinates relative to an external coordinate frame, along with its angular orientation.
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.3\textwidth]{images/robot_pose.png}
  \end{center}
  \caption{Robot pose, shown in global coordinate system}\label{fig:Robot Pose}
\end{figure}
The pose of the robot is described by the following vector $\begin{bsmallmatrix}x \\ y \\ \theta \end{bsmallmatrix}$.

The orientation of a robot is often called bearing or heading direction. The pose without orientation is called location.
The pose and the locations of objects in the environment may constitute the kinematic state $x_t$ of the robot-environment system.

\subsection{Probabilistic Kinematics}
The probabilistic kinematics model, or motion model plays the role of the state transition model in mobile robotics. This model is the familiar conditional density $\pcond{x_t}{u_t, x_{t-1}}$.

Here $x_t \ \text{and } x_{t-1}$ are both robot poses, and $u_t$ is a motion command. This model describes the posterior distribution over kinematic states that a robot assumes when executing the motion command $u_t$ at $x_{t-1}$.

We will discuss in detail two specific probabilistic motion models, both for mobile robots operating in the plane.
The first assumes taht the motion data $u_t$ specifies the velocity commands given to the robot's motors. Many commerical mobile robots are actuated by independent translational and rotational velocities.
The second model assumes that one has access to odometry information.

In practice, odometry models tend to be more accurate than velocity models, for the simple reason that most commercial robots do not execute velocity commands with the level of accuracy that can be obtained by measuring the revolution of the robots wheels.
However, odometry is only available after executing a motion command, hence it cannot be used for motion planning. Thus, odometry models are usualy applied for estimation, whereas velocity models are used for probabilistic motion planning.

\subsection{Velocity Motion Model}
The velocity motion model assumes that we can control a robot through two velocities, a rotational and a translational velocity.
We denote the translational velocity at time $t$ by $v_t$ and the rotational velocity by $\omega_t$. Hence we have $u_t = \begin{bsmallmatrix} v_t \\ \omega_t \end{bsmallmatrix}$.
We arbitrarily postulate that the positive rotational velocities induce a counterclockwise rotation, and that positive translational velocities correspond to forward motion.

It is possible to create an algorithm for computing the probability $\pcond{x_t}{u_t, x_{t-1}}$ of being at $x_t$ after executing $u_t$ begining at state $x_{t-1}$, assuming that the control is carried out for the fixed duration $\Delta t$.
The parameters $\alpha_1 \text{ to } \alpha_6$ are robot-specific motion error parameters.
The algorithm first calculated the controls of an error-free robot; the meaning of the individual variables in this calculation will become
more apparent below, when we derive it. These parameters are given by $\hat{v} \ \text{and } \hat{\omega}$.

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{images/motion_model_velocity.png}
  \end{center}
  \caption{Algorithm for computing $\pcond{x_t}{u_t,x_{t-1}}$ based on velocity information} \label{fig:motion_model_velocity}
\end{figure}

The function $\mathbf{prob}(x,b^2)$ models the motion error. It computes the probability of its parameter x under a zero-centered random variable with variance $b^2$.
Two possible implementations are shown in the next algorithm, for erro variables with normal distribution and triangular distribution, respectively.

\newpage

\subsection{Odometry Motion Model}

The velocity motion model discussed thus far uses the robot's velocity to compute posteriors over poses. Alternatively, one might want to use the odometry measurements as the bassis for calculating the robot's motion over time.
Odomtery is commonly obtained by integrating wheel encoder information; most commerical robots make such integrated pose estimation available in periodic time intervals.
This leads to a second motion model: the odometry motion model. This model uses odometry measurements in lieu of controls.\\

Practical experience suggests that odometry, while still erroneous, is usually more accurate then velocity.
Both suffer from drift and slippage, but velocity additionaly suffers from mismatch between ethe actual motion controllers and its crude mathematical model.
However, odometry is only available in retrospect, after the robot moded. This poses no problem for filter algorithms, however makes this information unusuable for accurate motion planning and control.

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.3\textwidth]{images/odom_model.png}
  \end{center}
  \caption{Odometry Model: The robot motion in the time interval $(t-1, t]$ is approximated by a rotation $\delta_{rot1}$ followed by a translation $\delta_{trans}$ and a second rotation $\delta_{rot2}$. The turns and translations are noisy}\label{fig:Odomtery Model}
\end{figure}

\subsubsection{Closed Form Solution}

Technically, odometric information are sensor measurements, not controls. To model odometry as measurements, the resulting Bayes filter would have to include the actual velocity as state variables, which increases the dimension of the state space.

\end{itemize}









\end{document}

